{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-14T20:16:25.224563Z","iopub.status.busy":"2023-07-14T20:16:25.224015Z","iopub.status.idle":"2023-07-14T20:18:04.268110Z","shell.execute_reply":"2023-07-14T20:18:04.266941Z","shell.execute_reply.started":"2023-07-14T20:16:25.224521Z"},"trusted":true},"outputs":[],"source":["#Code for installing important libraries\n","!pip install transformers\n","!pip install simpletransformers\n","! pip install -U git+https://github.com/huggingface/transformers.git\n","! pip install -U git+https://github.com/huggingface/accelerate.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:18:04.272049Z","iopub.status.busy":"2023-07-14T20:18:04.271707Z","iopub.status.idle":"2023-07-14T20:18:13.539795Z","shell.execute_reply":"2023-07-14T20:18:13.538819Z","shell.execute_reply.started":"2023-07-14T20:18:04.272015Z"},"trusted":true},"outputs":[],"source":["#Code for importing libraries important to code\n","import json\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:18:13.542017Z","iopub.status.busy":"2023-07-14T20:18:13.541252Z","iopub.status.idle":"2023-07-14T20:18:14.066329Z","shell.execute_reply":"2023-07-14T20:18:14.065314Z","shell.execute_reply.started":"2023-07-14T20:18:13.541982Z"},"trusted":true},"outputs":[],"source":["#Code for intializing data from train and validation datasets.\n","def load_dataset(file_name):\n","    data = []\n","    with open(file_name, encoding='utf8') as f:\n","        for line in f:\n","            example = json.loads(line)\n","            post_text = example['postText'][0]\n","            title = example['targetTitle']\n","            paragraphs = ' '.join(example['targetParagraphs'])\n","            label = example['tags'][0] if 'tags' in example else None\n","            if label in ['phrase', 'multi', 'passage']:\n","                data.append({'text': post_text + ' - ' + title + paragraphs, 'labels': label})\n","    return pd.DataFrame(data)\n","train_data = load_dataset(r'Your location where you stored train dataset in .jsonl format')\n","validation_data = load_dataset(r'Your location where you stored validation dataset in .jsonal format')\n","train_data['labels'] = train_data['labels'].replace(['phrase', 'multi', 'passage'],[0,1,2])\n","validation_data['labels'] = validation_data['labels'].replace(['phrase', 'multi', 'passage'],[0,1,2]) "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:18:14.086367Z","iopub.status.busy":"2023-07-14T20:18:14.085726Z","iopub.status.idle":"2023-07-14T20:18:14.130835Z","shell.execute_reply":"2023-07-14T20:18:14.129842Z","shell.execute_reply.started":"2023-07-14T20:18:14.086335Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"4\" halign=\"left\">text</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>count</th>\n","      <th>unique</th>\n","      <th>top</th>\n","      <th>freq</th>\n","    </tr>\n","    <tr>\n","      <th>labels</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1367</td>\n","      <td>1364</td>\n","      <td>Science Says This Is The Best Movie To Watch O...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>559</td>\n","      <td>559</td>\n","      <td>Passion is overrated — 7 work habits you need ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1274</td>\n","      <td>1274</td>\n","      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text                                                               \n","       count unique                                                top freq\n","labels                                                                     \n","0       1367   1364  Science Says This Is The Best Movie To Watch O...    2\n","1        559    559  Passion is overrated — 7 work habits you need ...    1\n","2       1274   1274  Wes Welker Wanted Dinner With Tom Brady, But P...    1"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#Code for checking total number of elements per label\n","train_data.groupby('labels').describe()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:18:14.149559Z","iopub.status.busy":"2023-07-14T20:18:14.149237Z","iopub.status.idle":"2023-07-14T20:18:15.495804Z","shell.execute_reply":"2023-07-14T20:18:15.494774Z","shell.execute_reply.started":"2023-07-14T20:18:14.149528Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3200\n","400\n"]}],"source":["#Code for removing stopwords from the train and validation dataset\n","import numpy as np\n","from gensim.parsing.preprocessing import remove_stopwords\n","def train_process(df):\n","    list1=[]\n","    for x in df['text']:\n","        list1.append([remove_stopwords(x)])\n","    return np.asarray(list1)\n","X_train = train_process(train_data)\n","X_val = train_process(validation_data)\n","        \n","print(len(X_train))\n","print(len(X_val))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:18:15.497824Z","iopub.status.busy":"2023-07-14T20:18:15.497428Z","iopub.status.idle":"2023-07-14T20:18:42.913695Z","shell.execute_reply":"2023-07-14T20:18:42.912692Z","shell.execute_reply.started":"2023-07-14T20:18:15.497773Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3200\n","400\n"]}],"source":["#Code for removing special characters from the train and validation dataset\n","characters = ['!','\"','#','$','%','&','(',')','*','+','/',':',';','<','=','>','@','^','`','|','~','\\t','[',']','{','}','\\\\','.','-']\n","for i in X_train:\n","    for j in characters:\n","        i[0] = i[0].replace(j,\"\")\n","\n","for i in X_val:\n","    for j in characters:\n","        i[0] = i[0].replace(j,\"\")\n","        \n","print(len(X_train))\n","print(len(X_val))        "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:18:42.918375Z","iopub.status.busy":"2023-07-14T20:18:42.918088Z","iopub.status.idle":"2023-07-14T20:18:42.929530Z","shell.execute_reply":"2023-07-14T20:18:42.928467Z","shell.execute_reply.started":"2023-07-14T20:18:42.918350Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3200, 3)\n","[[0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," ...\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]]\n"]}],"source":["#Code fo preprocessing y_train and y_val \n","import numpy as np\n","from keras.utils import to_categorical\n","def label_process(df):\n","    list1=[]\n","    for x in df['labels']:\n","        list1.append(x)\n","    return list1\n","Y_train = to_categorical(np.asarray(label_process(train_data)), num_classes=3)\n","Y_val = to_categorical(np.asarray(label_process(validation_data)), num_classes=3)\n","print(Y_train.shape)\n","print(Y_val)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:18:42.931916Z","iopub.status.busy":"2023-07-14T20:18:42.931109Z","iopub.status.idle":"2023-07-14T20:19:27.381724Z","shell.execute_reply":"2023-07-14T20:19:27.380735Z","shell.execute_reply.started":"2023-07-14T20:18:42.931883Z"},"trusted":true},"outputs":[],"source":["#Code for inatializing bert model (1024 embedding size) to use it as encoder for classification model.\n","bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n","bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_wwm_uncased_L-24_H-1024_A-16/4\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:19:27.383397Z","iopub.status.busy":"2023-07-14T20:19:27.383049Z","iopub.status.idle":"2023-07-14T20:19:30.583309Z","shell.execute_reply":"2023-07-14T20:19:30.582326Z","shell.execute_reply.started":"2023-07-14T20:19:27.383364Z"},"trusted":true},"outputs":[],"source":["#Code for creating embeddings through bert and intializing decoder using bidirectional GRU (the main structure of the model)\n","text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","preprocessed_text = bert_preprocess(text_input)\n","outputs = bert_encoder(preprocessed_text)\n","\n","l1 = tf.keras.layers.Dense(512, activation='leaky_relu', name='intermediate_layer')(outputs['sequence_output'])\n","l3 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, kernel_regularizer=None))(l1)\n","l6 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, kernel_regularizer=None))(l3)\n","l7 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, kernel_regularizer=None))(l6)\n","l8 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, kernel_regularizer=None))(l7)\n","l10 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, kernel_regularizer=None))(l8)\n","l12 = tf.keras.layers.Dense(128, activation='leaky_relu')(l10)\n","l = tf.keras.layers.Dense(3, activation='softmax', name=\"output\")(l12)\n","\n","# Use inputs and outputs to construct a final model\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:19:30.585084Z","iopub.status.busy":"2023-07-14T20:19:30.584728Z","iopub.status.idle":"2023-07-14T20:19:30.661323Z","shell.execute_reply":"2023-07-14T20:19:30.660624Z","shell.execute_reply.started":"2023-07-14T20:19:30.585051Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:19:30.662757Z","iopub.status.busy":"2023-07-14T20:19:30.662392Z","iopub.status.idle":"2023-07-14T20:19:30.707753Z","shell.execute_reply":"2023-07-14T20:19:30.706854Z","shell.execute_reply.started":"2023-07-14T20:19:30.662721Z"},"trusted":true},"outputs":[],"source":["#to intialize metrics for evaluation of the model and defining loss and other metrics important for training of the model\n","METRICS = [\n","        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall')\n","]\n","\n","model.compile(optimizer=tf.keras.optimizers.experimental.AdamW(learning_rate=0.0005),\n","              loss='categorical_crossentropy',\n","              metrics=METRICS)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:19:30.709775Z","iopub.status.busy":"2023-07-14T20:19:30.709184Z","iopub.status.idle":"2023-07-14T20:19:30.714961Z","shell.execute_reply":"2023-07-14T20:19:30.713817Z","shell.execute_reply.started":"2023-07-14T20:19:30.709743Z"},"trusted":true},"outputs":[],"source":["#Checkpoint to store model at best recall value on validation set on defined path.\n","checkpoint_filepath = 'Your path where you want to store your model'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_recall',\n","    mode='max',\n","    verbose=1,\n","    save_best_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:19:30.717111Z","iopub.status.busy":"2023-07-14T20:19:30.716507Z","iopub.status.idle":"2023-07-14T20:41:20.548375Z","shell.execute_reply":"2023-07-14T20:41:20.547395Z","shell.execute_reply.started":"2023-07-14T20:19:30.717077Z"},"trusted":true},"outputs":[],"source":["model.fit(X_train, Y_train, epochs=10, batch_size=5, validation_data=(X_val, Y_val), callbacks=[model_checkpoint_callback])"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:41:20.553039Z","iopub.status.busy":"2023-07-14T20:41:20.550266Z","iopub.status.idle":"2023-07-14T20:41:20.643766Z","shell.execute_reply":"2023-07-14T20:41:20.642765Z","shell.execute_reply.started":"2023-07-14T20:41:20.553004Z"},"trusted":true},"outputs":[],"source":["#Code for intializing data from test datasets.\n","def load_dataset(file_name):\n","    data = []\n","    with open(file_name, encoding='utf8') as f:\n","        for line in f:\n","            example = json.loads(line)\n","            post_text = example['postText'][0]\n","            title = example['targetTitle']\n","            id = example['id']\n","            paragraphs = ' '.join(example['targetParagraphs'])\n","            # label = example['tags'][0] if 'tags' in example else None\n","            # if label in ['phrase', 'multi', 'passage']:\n","            data.append({'id': id, 'text': post_text + ' - ' + title + paragraphs})\n","    return pd.DataFrame(data)\n","test_data = load_dataset('/kaggle/input/clickbait-detection-msci641-s23/test.jsonl')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:41:20.673462Z","iopub.status.busy":"2023-07-14T20:41:20.671055Z","iopub.status.idle":"2023-07-14T20:41:20.784191Z","shell.execute_reply":"2023-07-14T20:41:20.783168Z","shell.execute_reply.started":"2023-07-14T20:41:20.673426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["400\n"]}],"source":["#Code for removing stopwords from the test dataset\n","def preprocess(df):\n","    list1=[]\n","    for x in df['text']:\n","        list1.append([remove_stopwords(x)])\n","    return np.asarray(list1)\n","X_test = preprocess(test_data)\n","print(len(X_test))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:41:20.790723Z","iopub.status.busy":"2023-07-14T20:41:20.788373Z","iopub.status.idle":"2023-07-14T20:41:22.032601Z","shell.execute_reply":"2023-07-14T20:41:22.031487Z","shell.execute_reply.started":"2023-07-14T20:41:20.790690Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["400\n"]}],"source":["#Code for removing special characters from test datasets\n","characters = ['!','\"','#','$','%','&','(',')','*','+','/',':',';','<','=','>','@','^','`','|','~','\\t','[',']','{','}','\\\\','.','-']\n","for i in X_test:\n","    for j in characters:\n","        i[0] = i[0].replace(j,\"\")\n","print(len(X_test))            "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:41:22.034625Z","iopub.status.busy":"2023-07-14T20:41:22.034250Z","iopub.status.idle":"2023-07-14T20:42:26.334439Z","shell.execute_reply":"2023-07-14T20:42:26.333476Z","shell.execute_reply.started":"2023-07-14T20:41:22.034590Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 12s 602ms/step\n"]}],"source":["#Code for preloading trained model from model with best recall\n","model = tf.keras.models.load_model('Your path where you stored your model')\n","y_pred = model.predict(X_test)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:42:26.336896Z","iopub.status.busy":"2023-07-14T20:42:26.336510Z","iopub.status.idle":"2023-07-14T20:42:26.343526Z","shell.execute_reply":"2023-07-14T20:42:26.342549Z","shell.execute_reply.started":"2023-07-14T20:42:26.336861Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0.83839005, 0.09148254, 0.07012741],\n","       [0.05884722, 0.05188123, 0.88927156],\n","       [0.3443577 , 0.11773381, 0.5379085 ],\n","       ...,\n","       [0.7218329 , 0.18183222, 0.09633487],\n","       [0.1109169 , 0.04393053, 0.8451526 ],\n","       [0.83313924, 0.10784314, 0.05901757]], dtype=float32)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["y_pred"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:42:26.345761Z","iopub.status.busy":"2023-07-14T20:42:26.344764Z","iopub.status.idle":"2023-07-14T20:42:26.360772Z","shell.execute_reply":"2023-07-14T20:42:26.359527Z","shell.execute_reply.started":"2023-07-14T20:42:26.345724Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["400\n","    spoilerType\n","0        phrase\n","1       passage\n","2       passage\n","3        phrase\n","4        phrase\n","..          ...\n","395     passage\n","396      phrase\n","397      phrase\n","398     passage\n","399      phrase\n","\n","[400 rows x 1 columns]\n"]}],"source":["#Code for converting predicted values to actual labels\n","lst1=[]\n","for i in y_pred:\n","    if i[0]>i[1] and i[0]>i[2]:\n","        lst1.append('phrase')\n","    if i[1]>i[0] and i[1]>i[2]:\n","        lst1.append('multi')\n","    if i[2]>i[0] and i[2]>i[1]:\n","        lst1.append('passage')\n","print(len(lst1))        \n","df_1 = pd.DataFrame(lst1, columns=['spoilerType'])\n","print(df_1)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:43:40.986890Z","iopub.status.busy":"2023-07-14T20:43:40.986334Z","iopub.status.idle":"2023-07-14T20:43:41.016586Z","shell.execute_reply":"2023-07-14T20:43:41.015494Z","shell.execute_reply.started":"2023-07-14T20:43:40.986853Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["      id spoilerType\n","0      0      phrase\n","1      1     passage\n","2      2     passage\n","3      3      phrase\n","4      4      phrase\n","..   ...         ...\n","395  395     passage\n","396  396      phrase\n","397  397      phrase\n","398  398     passage\n","399  399      phrase\n","\n","[400 rows x 2 columns]\n"]}],"source":["final_df = pd.concat([test_data, df_1], axis=1)\n","final_df_1=final_df.drop(['text'], axis=1)\n","print(final_df_1)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T20:43:56.040564Z","iopub.status.busy":"2023-07-14T20:43:56.040198Z","iopub.status.idle":"2023-07-14T20:43:56.048540Z","shell.execute_reply":"2023-07-14T20:43:56.047592Z","shell.execute_reply.started":"2023-07-14T20:43:56.040534Z"},"trusted":true},"outputs":[],"source":["final_df_1.to_csv('prediction_task1_GRU.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
