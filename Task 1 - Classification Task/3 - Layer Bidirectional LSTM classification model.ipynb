{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-14T06:39:09.163427Z","iopub.status.busy":"2023-07-14T06:39:09.163022Z","iopub.status.idle":"2023-07-14T06:40:48.643621Z","shell.execute_reply":"2023-07-14T06:40:48.642409Z","shell.execute_reply.started":"2023-07-14T06:39:09.163396Z"},"trusted":true},"outputs":[],"source":["#Code for installing important libraries\n","!pip install transformers\n","!pip install simpletransformers\n","! pip install -U git+https://github.com/huggingface/transformers.git\n","! pip install -U git+https://github.com/huggingface/accelerate.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:40:48.648418Z","iopub.status.busy":"2023-07-14T06:40:48.648095Z","iopub.status.idle":"2023-07-14T06:40:57.802964Z","shell.execute_reply":"2023-07-14T06:40:57.801972Z","shell.execute_reply.started":"2023-07-14T06:40:48.648389Z"},"trusted":true},"outputs":[],"source":["#Code for importing libraries important to code\n","import json\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:40:57.804946Z","iopub.status.busy":"2023-07-14T06:40:57.804189Z","iopub.status.idle":"2023-07-14T06:40:58.334848Z","shell.execute_reply":"2023-07-14T06:40:58.333881Z","shell.execute_reply.started":"2023-07-14T06:40:57.804916Z"},"trusted":true},"outputs":[],"source":["#Code for intializing data from train and validation datasets.\n","def load_dataset(file_name):\n","    data = []\n","    with open(file_name, encoding='utf8') as f:\n","        for line in f:\n","            example = json.loads(line)\n","            post_text = example['postText'][0]\n","            title = example['targetTitle']\n","            paragraphs = ' '.join(example['targetParagraphs'])\n","            label = example['tags'][0] if 'tags' in example else None\n","            if label in ['phrase', 'multi', 'passage']:\n","                data.append({'text': post_text + ' - ' + title + paragraphs, 'labels': label})\n","    return pd.DataFrame(data)\n","train_data = load_dataset(r'Your location where you stored train dataset in .jsonl format')\n","validation_data = load_dataset(r'Your location where you stored validation dataset in .jsonal format')\n","train_data['labels'] = train_data['labels'].replace(['phrase', 'multi', 'passage'],[0,1,2])\n","validation_data['labels'] = validation_data['labels'].replace(['phrase', 'multi', 'passage'],[0,1,2]) "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:40:58.356504Z","iopub.status.busy":"2023-07-14T06:40:58.356067Z","iopub.status.idle":"2023-07-14T06:40:58.404984Z","shell.execute_reply":"2023-07-14T06:40:58.403898Z","shell.execute_reply.started":"2023-07-14T06:40:58.356441Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"4\" halign=\"left\">text</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>count</th>\n","      <th>unique</th>\n","      <th>top</th>\n","      <th>freq</th>\n","    </tr>\n","    <tr>\n","      <th>labels</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1367</td>\n","      <td>1364</td>\n","      <td>Science Says This Is The Best Movie To Watch O...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>559</td>\n","      <td>559</td>\n","      <td>Passion is overrated — 7 work habits you need ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1274</td>\n","      <td>1274</td>\n","      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text                                                               \n","       count unique                                                top freq\n","labels                                                                     \n","0       1367   1364  Science Says This Is The Best Movie To Watch O...    2\n","1        559    559  Passion is overrated — 7 work habits you need ...    1\n","2       1274   1274  Wes Welker Wanted Dinner With Tom Brady, But P...    1"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["#Code for checking total number of elements per label\n","train_data.groupby('labels').describe()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:40:58.427115Z","iopub.status.busy":"2023-07-14T06:40:58.426358Z","iopub.status.idle":"2023-07-14T06:40:59.773935Z","shell.execute_reply":"2023-07-14T06:40:59.772974Z","shell.execute_reply.started":"2023-07-14T06:40:58.427083Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3200\n","400\n"]}],"source":["#Code for removing stopwords from the train and validation dataset\n","import numpy as np\n","from gensim.parsing.preprocessing import remove_stopwords\n","def train_process(df):\n","    list1=[]\n","    for x in df['text']:\n","        list1.append([remove_stopwords(x)])\n","    return np.asarray(list1)\n","X_train = train_process(train_data)\n","X_val = train_process(validation_data)\n","        \n","print(len(X_train))\n","print(len(X_val))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:40:59.775973Z","iopub.status.busy":"2023-07-14T06:40:59.775410Z","iopub.status.idle":"2023-07-14T06:41:28.001022Z","shell.execute_reply":"2023-07-14T06:41:27.998888Z","shell.execute_reply.started":"2023-07-14T06:40:59.775938Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3200\n","400\n"]}],"source":["#Code for removing special characters from the train and validation dataset\n","characters = ['!','\"','#','$','%','&','(',')','*','+','/',':',';','<','=','>','@','^','`','|','~','\\t','[',']','{','}','\\\\','.','-']\n","for i in X_train:\n","    for j in characters:\n","        i[0] = i[0].replace(j,\"\")\n","\n","for i in X_val:\n","    for j in characters:\n","        i[0] = i[0].replace(j,\"\")\n","        \n","print(len(X_train))\n","print(len(X_val))        "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:41:28.005446Z","iopub.status.busy":"2023-07-14T06:41:28.005149Z","iopub.status.idle":"2023-07-14T06:41:28.015179Z","shell.execute_reply":"2023-07-14T06:41:28.014212Z","shell.execute_reply.started":"2023-07-14T06:41:28.005421Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3200, 3)\n","[[0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," ...\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]]\n"]}],"source":["#Code fo preprocessing y_train and y_val \n","import numpy as np\n","from keras.utils import to_categorical\n","def label_process(df):\n","    list1=[]\n","    for x in df['labels']:\n","        list1.append(x)\n","    return list1\n","Y_train = to_categorical(np.asarray(label_process(train_data)), num_classes=3)\n","Y_val = to_categorical(np.asarray(label_process(validation_data)), num_classes=3)\n","print(Y_train.shape)\n","print(Y_val)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:41:28.017598Z","iopub.status.busy":"2023-07-14T06:41:28.016626Z","iopub.status.idle":"2023-07-14T06:42:11.807143Z","shell.execute_reply":"2023-07-14T06:42:11.806155Z","shell.execute_reply.started":"2023-07-14T06:41:28.017565Z"},"trusted":true},"outputs":[],"source":["#Code for inatializing bert model (1024 embedding size) to use it as encoder for classification model.\n","bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n","bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_wwm_uncased_L-24_H-1024_A-16/4\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:42:11.808960Z","iopub.status.busy":"2023-07-14T06:42:11.808608Z","iopub.status.idle":"2023-07-14T06:42:14.281130Z","shell.execute_reply":"2023-07-14T06:42:14.280157Z","shell.execute_reply.started":"2023-07-14T06:42:11.808924Z"},"trusted":true},"outputs":[],"source":["#Code for creating embeddings through bert and intializing decoder using bidirectional LSTM (the main structure of the model)\n","text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","preprocessed_text = bert_preprocess(text_input)\n","outputs = bert_encoder(preprocessed_text)\n","\n","l1 = tf.keras.layers.Dense(512, activation='leaky_relu', name='intermediate_layer')(outputs['sequence_output'])\n","l3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, kernel_regularizer=None))(l1)\n","l6 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, kernel_regularizer=None))(l3)\n","l9 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, kernel_regularizer=None))(l6)\n","l12 = tf.keras.layers.Dense(128, activation='leaky_relu')(l9)\n","l = tf.keras.layers.Dense(3, activation='softmax', name=\"output\")(l12)\n","\n","# Use inputs and outputs to construct a final model\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:42:14.282981Z","iopub.status.busy":"2023-07-14T06:42:14.282647Z","iopub.status.idle":"2023-07-14T06:42:14.354130Z","shell.execute_reply":"2023-07-14T06:42:14.353392Z","shell.execute_reply.started":"2023-07-14T06:42:14.282945Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:42:14.355505Z","iopub.status.busy":"2023-07-14T06:42:14.355159Z","iopub.status.idle":"2023-07-14T06:42:14.399295Z","shell.execute_reply":"2023-07-14T06:42:14.398340Z","shell.execute_reply.started":"2023-07-14T06:42:14.355458Z"},"trusted":true},"outputs":[],"source":["#to intialize metrics for evaluation of the model and defining loss and other metrics important for training of the model\n","METRICS = [\n","        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall')\n","]\n","\n","model.compile(optimizer=tf.keras.optimizers.experimental.AdamW(learning_rate=0.0005),\n","              loss='categorical_crossentropy',\n","              metrics=METRICS)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:42:14.401545Z","iopub.status.busy":"2023-07-14T06:42:14.400617Z","iopub.status.idle":"2023-07-14T06:42:14.406420Z","shell.execute_reply":"2023-07-14T06:42:14.405535Z","shell.execute_reply.started":"2023-07-14T06:42:14.401510Z"},"trusted":true},"outputs":[],"source":["#Checkpoint to store model at best recall value on validation set on defined path.\n","checkpoint_filepath = 'Your path where you want to store your model'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_recall',\n","    mode='max',\n","    verbose=1,\n","    save_best_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T06:42:14.408518Z","iopub.status.busy":"2023-07-14T06:42:14.407618Z","iopub.status.idle":"2023-07-14T07:04:56.753219Z","shell.execute_reply":"2023-07-14T07:04:56.752226Z","shell.execute_reply.started":"2023-07-14T06:42:14.408485Z"},"trusted":true},"outputs":[],"source":["model.fit(X_train, Y_train, epochs=10, batch_size=5, validation_data=(X_val, Y_val), callbacks=[model_checkpoint_callback])"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T07:10:32.605963Z","iopub.status.busy":"2023-07-14T07:10:32.605554Z","iopub.status.idle":"2023-07-14T07:10:32.639089Z","shell.execute_reply":"2023-07-14T07:10:32.638208Z","shell.execute_reply.started":"2023-07-14T07:10:32.605935Z"},"trusted":true},"outputs":[],"source":["#Code for intializing data from test datasets.\n","def load_dataset(file_name):\n","    data = []\n","    with open(file_name, encoding='utf8') as f:\n","        for line in f:\n","            example = json.loads(line)\n","            post_text = example['postText'][0]\n","            title = example['targetTitle']\n","            id = example['id']\n","            paragraphs = ' '.join(example['targetParagraphs'])\n","            data.append({'id': id, 'text': post_text + ' - ' + title + paragraphs})\n","    return pd.DataFrame(data)\n","test_data = load_dataset('Your location where you stored test dataset in .jsonal format')"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T07:10:39.866171Z","iopub.status.busy":"2023-07-14T07:10:39.865800Z","iopub.status.idle":"2023-07-14T07:10:39.935112Z","shell.execute_reply":"2023-07-14T07:10:39.934007Z","shell.execute_reply.started":"2023-07-14T07:10:39.866142Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["400\n"]}],"source":["#Code for removing stopwords from the test dataset\n","def preprocess(df):\n","    list1=[]\n","    for x in df['text']:\n","        list1.append([remove_stopwords(x)])\n","    return np.asarray(list1)\n","X_test = preprocess(test_data)\n","print(len(X_test))"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T07:10:42.478620Z","iopub.status.busy":"2023-07-14T07:10:42.477901Z","iopub.status.idle":"2023-07-14T07:10:43.285526Z","shell.execute_reply":"2023-07-14T07:10:43.284548Z","shell.execute_reply.started":"2023-07-14T07:10:42.478585Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["400\n"]}],"source":["#Code for removing special characters from test datasets\n","characters = ['!','\"','#','$','%','&','(',')','*','+','/',':',';','<','=','>','@','^','`','|','~','\\t','[',']','{','}','\\\\','.','-']\n","for i in X_test:\n","    for j in characters:\n","        i[0] = i[0].replace(j,\"\")\n","print(len(X_test))            "]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 11s 567ms/step\n"]}],"source":["#Code for preloading trained model from model with best recall\n","model = tf.keras.models.load_model('Your path where you stored your model')\n","y_pred = model.predict(X_test)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T07:33:23.553932Z","iopub.status.busy":"2023-07-14T07:33:23.553491Z","iopub.status.idle":"2023-07-14T07:33:23.564564Z","shell.execute_reply":"2023-07-14T07:33:23.563514Z","shell.execute_reply.started":"2023-07-14T07:33:23.553894Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[9.5139837e-01, 4.6225131e-02, 2.3764812e-03],\n","       [1.7582175e-04, 5.5776825e-05, 9.9976844e-01],\n","       [9.7251725e-01, 1.2706693e-03, 2.6212117e-02],\n","       ...,\n","       [9.9985981e-01, 3.9150214e-05, 1.0111625e-04],\n","       [4.0712158e-04, 5.1842049e-05, 9.9954104e-01],\n","       [9.9998498e-01, 7.6849565e-06, 7.3347574e-06]], dtype=float32)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["y_pred"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T07:33:29.525375Z","iopub.status.busy":"2023-07-14T07:33:29.525005Z","iopub.status.idle":"2023-07-14T07:33:29.559727Z","shell.execute_reply":"2023-07-14T07:33:29.558512Z","shell.execute_reply.started":"2023-07-14T07:33:29.525345Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["400\n","    spoilerType\n","0        phrase\n","1       passage\n","2        phrase\n","3        phrase\n","4        phrase\n","..          ...\n","395     passage\n","396      phrase\n","397      phrase\n","398     passage\n","399      phrase\n","\n","[400 rows x 1 columns]\n"]}],"source":["#Code for converting predicted values to actual labels\n","lst1=[]\n","for i in y_pred:\n","    if i[0]>i[1] and i[0]>i[2]:\n","        lst1.append('phrase')\n","    if i[1]>i[0] and i[1]>i[2]:\n","        lst1.append('multi')\n","    if i[2]>i[0] and i[2]>i[1]:\n","        lst1.append('passage')\n","print(len(lst1))        \n","df_1 = pd.DataFrame(lst1, columns=['spoilerType'])\n","print(df_1)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T07:40:02.805290Z","iopub.status.busy":"2023-07-14T07:40:02.804903Z","iopub.status.idle":"2023-07-14T07:40:02.818903Z","shell.execute_reply":"2023-07-14T07:40:02.817774Z","shell.execute_reply.started":"2023-07-14T07:40:02.805259Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["      id spoilerType\n","0      0      phrase\n","1      1     passage\n","2      2      phrase\n","3      3      phrase\n","4      4      phrase\n","..   ...         ...\n","395  395     passage\n","396  396      phrase\n","397  397      phrase\n","398  398     passage\n","399  399      phrase\n","\n","[400 rows x 2 columns]\n"]}],"source":["final_df = pd.concat([test_data, df_1], axis=1)\n","final_df_1=final_df.drop(['text'], axis=1)\n","print(final_df_1)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T07:42:50.496691Z","iopub.status.busy":"2023-07-14T07:42:50.496303Z","iopub.status.idle":"2023-07-14T07:42:50.511790Z","shell.execute_reply":"2023-07-14T07:42:50.510645Z","shell.execute_reply.started":"2023-07-14T07:42:50.496660Z"},"trusted":true},"outputs":[],"source":["final_df_1.to_csv('prediction_task1_LSTM.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
